# OMG Empathy Challenge: A*STAR AI Submission
Repository for the A*AI Team's submission to the [OMG-Empathy Challenge 2019](https://www2.informatik.uni-hamburg.de/wtm/omgchallenges/omg_empathy.html).

- `audio` contains audio feature extraction code
- `text` contains text pre-processing code and the text-only model.
- `visual` contains visual feature extraction code and the visual-only model
- `multimodal` contains the multimodal model code

Requires PyTorch and scikit-learn. See read-mes in each sub-folder for more details on usage.


The saved model files that we used for our submission to the challenge are listed [here](https://www.dropbox.com/sh/al6fislp1xknqh8/AADzgxj0zfh22LX_RH06yq_Da?dl=0).

Detailed information about our models and implementation can be found in our paper - [A Multimodal LSTM for Predicting Listener Empathic Responses Over Time](https://arxiv.org/abs/1812.04891)
